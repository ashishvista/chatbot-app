# Domain-Specific RAG Chatbot Configuration
# Copy this file to .env and modify the values as needed

# === Model Configuration ===
# Language model for text generation
MODEL_NAME=microsoft/DialoGPT-medium

# Embedding model for document vectorization
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Directory to cache downloaded models
MODEL_PATH=./models

# === API Keys (Optional) ===
# OpenAI API key for compatibility (if using OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here

# Hugging Face API key for model downloads
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# === Gradio Web Interface ===
# Title displayed in the web interface
GRADIO_TITLE=ðŸ¤– Pediatric Care Assistant

# Description shown to users
GRADIO_DESCRIPTION=Ask questions about baby development, milestones, and pediatric care recommendations

# Port for the web interface
GRADIO_PORT=7860

# Host address (0.0.0.0 allows external access)
GRADIO_HOST=0.0.0.0

# === Document Processing ===
# Directory containing your source documents
DOCUMENTS_PATH=./data/documents

# Directory to store the vector database
VECTOR_STORE_PATH=./data/vector_store

# Size of text chunks when splitting documents
CHUNK_SIZE=1000

# Overlap between consecutive chunks
CHUNK_OVERLAP=200

# === RAG Pipeline Settings ===
# Number of similar documents to retrieve for each query
RETRIEVAL_K=4

# Maximum number of new tokens to generate
MAX_NEW_TOKENS=512

# Temperature for text generation (0.0 = deterministic, 1.0 = creative)
TEMPERATURE=0.7

# Top-p sampling parameter
TOP_P=0.9

# === System Configuration ===
# Enable detailed logging (true/false)
DEBUG_MODE=false

# Device for model inference (auto, cpu, cuda)
DEVICE=auto

# === Example Configurations for Different Use Cases ===

# For CPU-only systems (slower but works everywhere):
# MODEL_NAME=microsoft/DialoGPT-small
# DEVICE=cpu
# CHUNK_SIZE=500
# RETRIEVAL_K=3

# For GPU systems (faster inference):
# MODEL_NAME=microsoft/DialoGPT-medium
# DEVICE=cuda
# CHUNK_SIZE=1000
# RETRIEVAL_K=4

# For better quality (requires more memory):
# MODEL_NAME=microsoft/DialoGPT-large
# EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
# MAX_NEW_TOKENS=1024
